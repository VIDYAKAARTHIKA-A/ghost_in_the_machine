# ghost_in_the_machine

The Ghost in the Machine
Stylometric Detection of AI vs Human Authorship

â€œLe style, c'est l'homme mÃªmeâ€ â€” Georges-Louis Leclerc
(Style is the man himself.)

ðŸ“Œ Project Overview

This project investigates whether machine-generated text can be reliably distinguished from human-authored text using stylometric analysis, classical machine learning, deep learning, and adversarial text evolution.

The pipeline explores:

Statistical authorship fingerprinting

Multi-tier AI detection models

Model interpretability

Genetic algorithm-based adversarial text evolution

ðŸŽ¯ Objectives

Build an authorship-controlled dataset.

Prove that AI and human texts are mathematically distinct.

Train multi-tier detection models.

Explain model decision-making.

Attempt to evolve AI text that bypasses detection.

ðŸ“š Task 0 â€” Dataset Construction
â€œThe Library of Babelâ€
ðŸ‘©â€ðŸ’» Human Corpus

Texts were collected from Project Gutenberg.

Selected Authors
Charles Dickens

David Copperfield

Great Expectations

Hard Times

Oliver Twist

A Tale of Two Cities

Jane Austen

Emma

Northanger Abbey

Persuasion

Pride and Prejudice

Sense and Sensibility

ðŸ§¹ Data Cleaning

The following preprocessing steps were applied:

Removed Gutenberg headers and footers

Normalized whitespace

Extracted paragraph-level text

Filtered paragraphs between 100â€“200 words

Final Human Dataset

3328 paragraphs

ðŸ§  Topic Control

To ensure classification relies on style rather than topic, thematic extraction was performed.

Identified Core Themes

Social Class and Economic Inequality

Marriage and Courtship

Moral Character and Virtue

Pursuit of Happiness

Urban Social Transformation

Reputation and Honor

Education and Self-Improvement

Friendship and Human Relationships

ðŸ¤– AI Dataset Generation
Class 2 â€” AI Neutral

Generated using Gemini 2.5 Flash Lite

500 paragraphs

Topic-controlled

No stylistic constraints

ðŸŽ­ Class 3 â€” AI Styled

AI was prompted to mimic author-specific styles.

Austen Style Characteristics

Free indirect discourse

Social irony

Third-person narration

Regency vocabulary

Dickens Style Characteristics

Narrative storytelling

Emotional vividness

Mixed sentence structures

Victorian vocabulary

Total:

500 styled AI paragraphs

âœï¸ Stylistic Differences Between Austen and Dickens
Feature	Austen	Dickens
Narrative Perspective	Third-person	Often First-person
Tone	Ironic, restrained	Emotional, dramatic
Sentence Structure	Balanced, polished	Variable and expressive
Focus	Social psychology	Social realism
Vocabulary	Elegant, subtle	Descriptive, vivid
Characterization	Internal thought driven	Plot-driven storytelling
ðŸ”¬ Task 1 â€” Stylometric Fingerprint Analysis

The goal was to prove that the three text classes are mathematically distinguishable.

ðŸ“Š Lexical Richness Metrics
1. Type Token Ratio (TTR)
Measures vocabulary diversity.

2. Hapax Legomena
Words appearing exactly once in a sample.

Higher hapax usage typically indicates:
Greater lexical spontaneity
Reduced repetitive phrasing

3. Hapax Percentage:
Hapax%=
UniqueWords
HapaxWordsÃ—100

ðŸ§© Syntactic Complexity Metrics
POS Adjective-Noun Ratio

Measures descriptive density:
Adj/NounRatio=
Nouns
Adjectives
	
Dependency Tree Depth

Calculated using SpaCy.

Higher values indicate:

Nested grammatical complexity

Longer hierarchical sentence structures

Average Sentence Length

Captures rhythmic variation and structural complexity.

ðŸ“– Readability
Flesch-Kincaid Grade Level

Estimates required education level to understand text.

âœ’ï¸ Punctuation Density

Tracked frequency of:

Commas

Periods

Semicolons

Colons

Exclamation Marks

Question Marks

ðŸ“ˆ Mathematical Distinctness Evidence
Key Observations
Feature	Human	AI Neutral	AI Styled
TTR	Lower	Highest	Moderate
Hapax Usage	Lower	Higher	Highest
Syntax Depth	Moderate	Lowest	Highest
Sentence Length	Variable	Short	Long
Readability	Mixed	Simple	Complex

These differences confirm statistically separable class distributions.

ðŸ•µï¸ Task 2 â€” Multi-Tier AI Detector
Tier A â€” Statistical Detector
Models Used

Random Forest

XGBoost

Input Features

Stylometric numerical metrics from Task 1.

Results
Model	Accuracy
XGBoost	95.9%
Feature Importance Findings

Most predictive features:

Hapax Percentage

Semicolon Usage

Readability Scores

Lexical Diversity

Tier B â€” Semantic Detector
Method

GloVe word embeddings

Feedforward neural network

What are GloVe Embeddings?

GloVe learns vector representations of words using global word co-occurrence statistics.

It captures:

Semantic similarity

Contextual relationships

Narrative tone

Results

Accuracy: 99%

This indicates AI struggles to perfectly replicate deeper semantic narrative patterns.

Tier C â€” Transformer Detector
DistilBERT

A compressed transformer model retaining most of BERTâ€™s language understanding capability while reducing computational cost.

LoRA (Low Rank Adaptation)

Efficient fine-tuning method where:

Only a small fraction of model parameters are trained

Preserves pretrained knowledge

Reduces memory and training cost

Training Summary

Only ~1.09% parameters trained

GPU acceleration used

Results

Accuracy: 100%

This suggests transformers capture:

Sentence rhythm

Contextual coherence

Narrative voice

ðŸ” Task 3 â€” Explainability

Due to near-perfect classification performance, interpretability was theoretically analyzed.

Models likely detect AI-specific linguistic signals such as:

Over-structured phrasing

Excess lexical novelty

Uniform narrative rhythm

ðŸ§¬ Task 4 â€” Genetic Algorithm Adversarial Attack
â€œThe Turing Testâ€
Objective

Attempt to evolve AI text until the detector classifies it as Human (>90%).

Genetic Algorithm Workflow
Initial Population

10 AI-generated paragraphs

Fitness Function

Human classification probability from Tier C model.

Selection

Top 3 highest-scoring paragraphs retained.

Mutation Strategies
Rhythm Mutation

Alters sentence flow and pacing.

Vocabulary Mutation

Replaces formal vocabulary with natural alternatives.

Inconsistency Injection

Introduces subtle human-like imperfections.

Archaic Vocabulary

Adds rare but natural lexical choices.

Punctuation Variation

Introduces expressive punctuation diversity.

Structural Complexity

Adds subordinate clauses and narrative detail.

Evolution Results

Generations executed: 10

Best Human Score Achieved: 0.51

Target Score: 0.90

Interpretation

The plateau suggests:

The detector captures deep linguistic signals

Simple stylistic perturbations are insufficient to bypass detection

ðŸ“Š Key Findings

Human and AI text are mathematically separable.

Statistical stylometry alone achieves high accuracy.

Semantic embeddings dramatically improve detection.

Transformer-based detectors nearly eliminate classification errors.

Adversarial text evolution remains challenging.

ðŸ›  Technology Stack

Python

SpaCy

Scikit-Learn

XGBoost

PyTorch

HuggingFace Transformers

LoRA (PEFT)

Gemini API

Matplotlib / Seaborn
